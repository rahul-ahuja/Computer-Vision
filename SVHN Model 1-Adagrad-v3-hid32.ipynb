{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_data = pickle.load( open( \"total_data.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33401, 64, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data[0:33401].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_labels = pickle.load( open( \"total_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33401, 5, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_test_data = pickle.load( open( \"total_test_data.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_test_labels = pickle.load( open( \"total_test_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13066, 64, 64, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test_data = total_test_data[0:13066]\n",
    "total_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13066, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test_labels[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy2(pred_labels1,pred_labels2,pred_labels3,pred_labels4,pred_labels5,true_labels1,true_labels2,true_labels3,true_labels4,true_labels5):\n",
    "    ar = np.sum((np.array([np.argmax(pred_labels1, 1), np.argmax(pred_labels2, 1),np.argmax(pred_labels3, 1),np.argmax(pred_labels4, 1),np.argmax(pred_labels5, 1)]) \n",
    "  == np.array([np.argmax(true_labels1, 1),np.argmax(true_labels2, 1),np.argmax(true_labels3, 1),np.argmax(true_labels4, 1),np.argmax(true_labels5, 1)])),axis=0)\n",
    "    count = 0\n",
    "    for elem in ar:\n",
    "        if elem == 5:\n",
    "            count = count + 1\n",
    "    return ((100.0 * count)/pred_labels1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5 #Convolution filters are 5 x 5 pixels.\n",
    "depth = 16\n",
    "num_hidden = 32  # Number of neurons in fully-connected layer.\n",
    "image_size = 64\n",
    "num_labels = 11\n",
    "num_channels = 1 # grayscale # Number of colour channels for the images: 1 channel for gray-scale.\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels0 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  #tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_test_labels0 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_test_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_test_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_test_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_test_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    \n",
    "\n",
    "# Variables.\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "        [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "        [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "        [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    layer4_weights_out1 = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1), dtype= tf.float32, name = \"weightsout1\")\n",
    "    layer4_biases_out1 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name = \"biasout1\")\n",
    "    layer4_weights_out2 = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1), dtype= tf.float32, name = \"weightsout2\")\n",
    "    layer4_biases_out2 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name = \"biasout2\")\n",
    "    layer4_weights_out3 = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1), dtype= tf.float32, name = \"weightsout3\")\n",
    "    layer4_biases_out3 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name = \"biasout3\")\n",
    "    layer4_weights_out4 = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1), dtype= tf.float32, name = \"weightsout4\")\n",
    "    layer4_biases_out4 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name = \"biasout4\")\n",
    "    layer4_weights_out5 = tf.Variable(tf.truncated_normal(\n",
    "        [num_hidden, num_labels], stddev=0.1), dtype= tf.float32, name = \"weightsout5\")\n",
    "    layer4_biases_out5 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name = \"biasout5\")\n",
    "\n",
    "\n",
    "\n",
    "  # Model.\n",
    "    def model(data):\n",
    "        \n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        h_pool1 = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(h_pool1, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        #h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        h_pool2 = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "        shape = h_pool2.get_shape().as_list()\n",
    "        reshape = tf.reshape(h_pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        logits1 = tf.matmul(hidden, layer4_weights_out1) + layer4_biases_out1\n",
    "        logits2 = tf.matmul(hidden, layer4_weights_out2) + layer4_biases_out2\n",
    "        logits3 = tf.matmul(hidden, layer4_weights_out3) + layer4_biases_out3\n",
    "        logits4 = tf.matmul(hidden, layer4_weights_out4) + layer4_biases_out4\n",
    "        logits5 = tf.matmul(hidden, layer4_weights_out5) + layer4_biases_out5\n",
    "        \n",
    "        return logits1, logits2, logits3, logits4, logits5\n",
    "\n",
    "\n",
    "  \n",
    "  # Training computation.\n",
    "    logits1, logits2, logits3, logits4, logits5 = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits1, tf_train_labels0)) + tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits2, tf_train_labels1)) + tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits3, tf_train_labels2)) + tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits4, tf_train_labels3)) + tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits5, tf_train_labels4))\n",
    "    \n",
    "    #global_step = tf.Variable(0)\n",
    "    #learning_rate = tf.train.exponential_decay(0.1, global_step, 1000, 0.96, staircase=True )\n",
    "  # Optimizer.\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate=0.025, momentum = 0.9).minimize(loss)\n",
    "    optimizer = tf.train.AdagradOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "# Predictions for the training, validation, and test data.\n",
    "    train_prediction1 = tf.nn.softmax(logits1)\n",
    "    train_prediction2 = tf.nn.softmax(logits2)\n",
    "    train_prediction3 = tf.nn.softmax(logits3)\n",
    "    train_prediction4 = tf.nn.softmax(logits4)\n",
    "    train_prediction5 = tf.nn.softmax(logits5)\n",
    "    #valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction1 = tf.nn.softmax(model(tf_test_dataset)[0])\n",
    "    test_prediction2 = tf.nn.softmax(model(tf_test_dataset)[1])\n",
    "    test_prediction3 = tf.nn.softmax(model(tf_test_dataset)[2])\n",
    "    test_prediction4 = tf.nn.softmax(model(tf_test_dataset)[3])\n",
    "    test_prediction5 = tf.nn.softmax(model(tf_test_dataset)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 16.267078\n",
      "Minibatch accuracy of 1st digit: 0.0%\n",
      "Minibatch accuracy: 5.0%\n",
      "Minibatch accuracy of sequence: 0.0%\n",
      "Minibatch loss at step 500: 5.738986\n",
      "Minibatch accuracy of 1st digit: 12.5%\n",
      "Minibatch accuracy: 65.0%\n",
      "Minibatch accuracy of sequence: 0.0%\n",
      "Minibatch loss at step 1000: 6.612051\n",
      "Minibatch accuracy of 1st digit: 37.5%\n",
      "Minibatch accuracy: 60.0%\n",
      "Minibatch accuracy of sequence: 6.2%\n",
      "Minibatch loss at step 1500: 5.434232\n",
      "Minibatch accuracy of 1st digit: 37.5%\n",
      "Minibatch accuracy: 66.2%\n",
      "Minibatch accuracy of sequence: 6.2%\n",
      "Minibatch loss at step 2000: 6.687022\n",
      "Minibatch accuracy of 1st digit: 43.8%\n",
      "Minibatch accuracy: 60.0%\n",
      "Minibatch accuracy of sequence: 6.2%\n",
      "Minibatch loss at step 2500: 5.342072\n",
      "Minibatch accuracy of 1st digit: 62.5%\n",
      "Minibatch accuracy: 63.8%\n",
      "Minibatch accuracy of sequence: 0.0%\n",
      "Minibatch loss at step 3000: 3.756052\n",
      "Minibatch accuracy of 1st digit: 43.8%\n",
      "Minibatch accuracy: 77.5%\n",
      "Minibatch accuracy of sequence: 25.0%\n",
      "Minibatch loss at step 3500: 4.367487\n",
      "Minibatch accuracy of 1st digit: 43.8%\n",
      "Minibatch accuracy: 73.8%\n",
      "Minibatch accuracy of sequence: 12.5%\n",
      "Minibatch loss at step 4000: 3.735777\n",
      "Minibatch accuracy of 1st digit: 68.8%\n",
      "Minibatch accuracy: 73.8%\n",
      "Minibatch accuracy of sequence: 18.8%\n",
      "Minibatch loss at step 4500: 3.552976\n",
      "Minibatch accuracy of 1st digit: 87.5%\n",
      "Minibatch accuracy: 76.2%\n",
      "Minibatch accuracy of sequence: 18.8%\n",
      "Minibatch loss at step 5000: 2.885586\n",
      "Minibatch accuracy of 1st digit: 68.8%\n",
      "Minibatch accuracy: 80.0%\n",
      "Minibatch accuracy of sequence: 25.0%\n",
      "Minibatch loss at step 5500: 3.781700\n",
      "Minibatch accuracy of 1st digit: 62.5%\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch accuracy of sequence: 25.0%\n",
      "Minibatch loss at step 6000: 3.905428\n",
      "Minibatch accuracy of 1st digit: 68.8%\n",
      "Minibatch accuracy: 78.8%\n",
      "Minibatch accuracy of sequence: 43.8%\n",
      "Minibatch loss at step 6500: 2.913687\n",
      "Minibatch accuracy of 1st digit: 81.2%\n",
      "Minibatch accuracy: 78.8%\n",
      "Minibatch accuracy of sequence: 31.2%\n",
      "Minibatch loss at step 7000: 2.682027\n",
      "Minibatch accuracy of 1st digit: 75.0%\n",
      "Minibatch accuracy: 83.8%\n",
      "Minibatch accuracy of sequence: 50.0%\n",
      "Minibatch loss at step 7500: 2.965526\n",
      "Minibatch accuracy of 1st digit: 68.8%\n",
      "Minibatch accuracy: 82.5%\n",
      "Minibatch accuracy of sequence: 43.8%\n",
      "Minibatch loss at step 8000: 2.908171\n",
      "Minibatch accuracy of 1st digit: 75.0%\n",
      "Minibatch accuracy: 78.8%\n",
      "Minibatch accuracy of sequence: 37.5%\n",
      "Minibatch loss at step 8500: 2.374192\n",
      "Minibatch accuracy of 1st digit: 75.0%\n",
      "Minibatch accuracy: 82.5%\n",
      "Minibatch accuracy of sequence: 43.8%\n",
      "Minibatch loss at step 9000: 2.882427\n",
      "Minibatch accuracy of 1st digit: 81.2%\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch accuracy of sequence: 37.5%\n",
      "Minibatch loss at step 9500: 3.555647\n",
      "Minibatch accuracy of 1st digit: 62.5%\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch accuracy of sequence: 37.5%\n",
      "Minibatch loss at step 10000: 3.191533\n",
      "Minibatch accuracy of 1st digit: 75.0%\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch accuracy of sequence: 50.0%\n",
      "Test accuracy of mini-batch: 87.5%\n",
      "Test accuracy of sequence:  50.0%\n",
      "Test accuracy of mini-batch: 76.2%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 85.0%\n",
      "Test accuracy of sequence:  56.2%\n",
      "Test accuracy of mini-batch: 77.5%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 77.5%\n",
      "Test accuracy of sequence:  37.5%\n",
      "Test accuracy of mini-batch: 85.0%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 91.2%\n",
      "Test accuracy of sequence:  68.8%\n",
      "Test accuracy of mini-batch: 83.8%\n",
      "Test accuracy of sequence:  50.0%\n",
      "Test accuracy of mini-batch: 83.8%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 87.5%\n",
      "Test accuracy of sequence:  56.2%\n",
      "Test accuracy of mini-batch: 88.8%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 83.8%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Test accuracy of mini-batch: 86.2%\n",
      "Test accuracy of sequence:  62.5%\n",
      "Test accuracy of mini-batch: 83.8%\n",
      "Test accuracy of sequence:  37.5%\n",
      "Test accuracy of mini-batch: 78.8%\n",
      "Test accuracy of sequence:  25.0%\n",
      "Test accuracy of mini-batch: 86.2%\n",
      "Test accuracy of sequence:  50.0%\n",
      "Test accuracy of mini-batch: 78.8%\n",
      "Test accuracy of sequence:  43.8%\n",
      "Total Test accuracy : 83.6%\n",
      "Total Test accuracy sequence: 47.1%\n",
      "Time usage: 0:13:37\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "t_num_steps = 13066 // 16\n",
    "test_acc = []\n",
    "test_acc_seq = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "        \n",
    "        # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (total_labels[:,0].shape[0] - batch_size)\n",
    "        batch_data = total_data[0:33401][offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels0 = total_labels[:,0][offset:(offset + batch_size), :]\n",
    "        batch_labels1 = total_labels[:,1][offset:(offset + batch_size), :]\n",
    "        batch_labels2 = total_labels[:,2][offset:(offset + batch_size), :]\n",
    "        batch_labels3 = total_labels[:,3][offset:(offset + batch_size), :]\n",
    "        batch_labels4 = total_labels[:,4][offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels0 : batch_labels0,\n",
    "                     tf_train_labels1 : batch_labels1, tf_train_labels2 : batch_labels2, \n",
    "                     tf_train_labels3 : batch_labels3, tf_train_labels4 : batch_labels4}\n",
    "        _, l, predictions1, predictions2, predictions3, predictions4, predictions5 = session.run(\n",
    "          [optimizer, loss, train_prediction1, train_prediction2, train_prediction3,\n",
    "           train_prediction4, train_prediction5], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "          print('Minibatch loss at step %d: %f' % (step, l))\n",
    "          a1 = accuracy(predictions1, batch_labels0)\n",
    "          a2 = accuracy(predictions2, batch_labels1)\n",
    "          a3 = accuracy(predictions3, batch_labels2)\n",
    "          a4 = accuracy(predictions4, batch_labels3)\n",
    "          a5 = accuracy(predictions5, batch_labels4)\n",
    "          print('Minibatch accuracy of 1st digit: %.1f%%' % accuracy(predictions1, batch_labels0))\n",
    "          print('Minibatch accuracy: %.1f%%' % np.mean(np.array((a1,a2,a3,a4,a5),dtype = np.float32)))\n",
    "          print('Minibatch accuracy of sequence: %.1f%%' % accuracy2(predictions1,predictions2,\n",
    "                                                                     predictions3,predictions4,\n",
    "                                                                     predictions5,batch_labels0,\n",
    "                                                                     batch_labels1,batch_labels2,\n",
    "                                                                     batch_labels3,batch_labels4))\n",
    "        \n",
    "    for step in range(t_num_steps):\n",
    "        offset = (step * batch_size) % (total_test_labels[:,0].shape[0] - batch_size)\n",
    "        batch_test_data = total_test_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_test_labels0 = total_test_labels[:,0][offset:(offset + batch_size), :]\n",
    "        batch_test_labels1 = total_test_labels[:,1][offset:(offset + batch_size), :]\n",
    "        batch_test_labels2 = total_test_labels[:,2][offset:(offset + batch_size), :]\n",
    "        batch_test_labels3 = total_test_labels[:,3][offset:(offset + batch_size), :]\n",
    "        batch_test_labels4 = total_test_labels[:,4][offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_test_dataset : batch_test_data, tf_test_labels0 : batch_test_labels0,\n",
    "                     tf_test_labels1 : batch_test_labels1, tf_test_labels2 : batch_test_labels2, \n",
    "                     tf_test_labels3 : batch_test_labels3, tf_test_labels4 : batch_test_labels4}\n",
    "        t_prediction1, t_prediction2, t_prediction3, t_prediction4, t_prediction5 = session.run(\n",
    "          [test_prediction1, test_prediction2, test_prediction3,\n",
    "           test_prediction4, test_prediction5], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 50 == 0):\n",
    "            #print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            t1 = accuracy(t_prediction1, batch_test_labels0)\n",
    "            t2 = accuracy(t_prediction2, batch_test_labels1)\n",
    "            t3 = accuracy(t_prediction3, batch_test_labels2)\n",
    "            t4 = accuracy(t_prediction4, batch_test_labels3)\n",
    "            t5 = accuracy(t_prediction5, batch_test_labels4)\n",
    "            print('Test accuracy of mini-batch: %.1f%%' % np.mean(np.array((t1,t2,t3,t4,t5),dtype = np.float32)))\n",
    "            test_acc.append(np.mean(np.array((t1,t2,t3,t4,t5),dtype = np.float32)))\n",
    "            t_acc_seq = accuracy2(t_prediction1, t_prediction2, t_prediction3, t_prediction4,\n",
    "                                  t_prediction5, batch_test_labels0, batch_test_labels1,\n",
    "                                  batch_test_labels2, batch_test_labels3, batch_test_labels4)\n",
    "            print('Test accuracy of sequence:  %.1f%%' % t_acc_seq)\n",
    "            test_acc_seq.append(t_acc_seq)\n",
    "            \n",
    "            \n",
    "    print('Total Test accuracy : %.1f%%' % np.mean(test_acc))\n",
    "    print('Total Test accuracy sequence: %.1f%%' % np.mean(test_acc_seq))\n",
    "    \n",
    "        # Ending time.\n",
    "    end_time = time.time()\n",
    "    \n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "[0,0,6.2,6.2,6.2,0,25,12.5,18.8,18.8,25,25,43.8,31.2,50,43.8,37.3,37.3,43.8,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAEpCAYAAAAOMlxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe65e936d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,0,6.2,6.2,6.2,0,25,12.5,18.8,18.8,25,25,43.8,31.2,50,43.8,37.3,37.3,43.8,37.5,50],\n",
    "         [x for x in range(0,10500,500)])\n",
    "plt.suptitle('Training Accuracy level as per metric two', fontsize=20)\n",
    "plt.xlabel('Percentage of Accuracy Level', fontsize=18)\n",
    "plt.ylabel('Number of steps', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
